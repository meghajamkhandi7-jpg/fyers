"""
Wrap-Up Workflow - LangGraph-based workflow for collecting and submitting artifacts
when the agent reaches iteration limit without completing the task.

This module provides a clean, modular workflow that:
1. Lists all artifacts in the E2B sandbox
2. Asks the LLM to choose which artifacts to submit
3. Downloads chosen artifacts
4. Submits them for evaluation

Uses LangGraph for maintainability and clear separation from main agent flow.
"""

import os
import json
from typing import Dict, List, Optional, TypedDict, Annotated
from pathlib import Path

from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI


class WrapUpState(TypedDict):
    """State for wrap-up workflow"""
    date: str
    task_id: str
    task_prompt: str
    sandbox_dir: str
    conversation_history: List[Dict]  # Agent's conversation messages
    available_artifacts: List[str]
    chosen_artifacts: List[str]
    downloaded_paths: List[str]
    submission_result: Optional[Dict]
    error: Optional[str]
    llm_decision: Optional[str]


class WrapUpWorkflow:
    """
    LangGraph-based workflow for artifact collection and submission
    when iteration limit is reached without task completion.
    """
    
    def __init__(self, llm: Optional[ChatOpenAI] = None, logger=None):
        """
        Initialize wrap-up workflow
        
        Args:
            llm: Language model for decision-making (if None, creates default)
            logger: Logger instance for output
        """
        self.llm = llm or ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
        self.logger = logger
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow"""
        
        # Define the graph
        workflow = StateGraph(WrapUpState)
        
        # Add nodes
        workflow.add_node("list_artifacts", self._list_artifacts_node)
        workflow.add_node("decide_submission", self._decide_submission_node)
        workflow.add_node("download_artifacts", self._download_artifacts_node)
        workflow.add_node("submit_work", self._submit_work_node)
        
        # Define edges
        workflow.set_entry_point("list_artifacts")
        workflow.add_edge("list_artifacts", "decide_submission")
        
        # Conditional edge: if chosen_artifacts, download them; else end
        workflow.add_conditional_edges(
            "decide_submission",
            self._should_download,
            {
                "download": "download_artifacts",
                "end": END
            }
        )
        
        workflow.add_edge("download_artifacts", "submit_work")
        workflow.add_edge("submit_work", END)
        
        return workflow.compile()
    
    def _should_download(self, state: WrapUpState) -> str:
        """Determine if we should download artifacts"""
        if state.get("chosen_artifacts") and len(state["chosen_artifacts"]) > 0:
            return "download"
        return "end"
    
    def _list_artifacts_node(self, state: WrapUpState) -> WrapUpState:
        """List all artifacts in the E2B sandbox"""
        try:
            self._log("ðŸ” Listing artifacts in E2B sandbox...")
            
            from livebench.tools.productivity.code_execution_sandbox import SessionSandbox
            
            session_sandbox = SessionSandbox.get_instance()
            
            # Get the current date to ensure we connect to the right sandbox
            date = state.get("date", "unknown")
            sandbox = session_sandbox.get_or_create_sandbox()
            
            self._log(f"   ðŸ“¦ Connected to sandbox: {session_sandbox.sandbox_id}")
            
            artifact_paths = []
            artifact_extensions = ['.txt', '.docx', '.xlsx', '.csv', '.pdf', 
                                  '.png', '.jpg', '.jpeg', '.json', '.md', '.pptx']
            
            # Scan multiple directories where artifacts might be
            directories_to_scan = ["/tmp", "/home/user", "/home/user/artifacts"]
            
            for base_dir in directories_to_scan:
                try:
                    self._log(f"   ðŸ” Scanning directory: {base_dir}")
                    
                    # E2B files.list() returns a list of file info objects
                    files_list = sandbox.files.list(base_dir)
                    
                    self._log(f"      Found {len(files_list)} items in {base_dir}")
                    
                    for file_info in files_list:
                        # E2B file info object has 'name' and 'type' attributes
                        # type can be 'file' or 'dir'
                        file_type = getattr(file_info, 'type', 'file')
                        file_name = getattr(file_info, 'name', str(file_info))
                        
                        # Skip directories and hidden files
                        if file_type == 'dir':
                            continue
                        if file_name.startswith('.'):
                            continue
                        
                        # Check if it's an artifact type
                        if any(file_name.endswith(ext) for ext in artifact_extensions):
                            # Construct full path
                            full_path = f"{base_dir}/{file_name}"
                            
                            # Avoid duplicates
                            if full_path not in artifact_paths:
                                artifact_paths.append(full_path)
                                self._log(f"      âœ… Found artifact: {file_name}")
                    
                except Exception as e:
                    # Directory might not exist or permission issues
                    self._log(f"      âš ï¸ Could not list {base_dir}: {str(e)}")
                    continue
            
            state["available_artifacts"] = artifact_paths
            
            if artifact_paths:
                self._log(f"\n   âœ… Total artifacts found: {len(artifact_paths)}")
                for i, path in enumerate(artifact_paths[:10], 1):
                    self._log(f"      {i}. {os.path.basename(path)} ({path})")
                
                if len(artifact_paths) > 10:
                    self._log(f"      ... and {len(artifact_paths) - 10} more")
            else:
                self._log(f"   âš ï¸ No artifacts found in any directory")
                self._log(f"      Scanned: {', '.join(directories_to_scan)}")
            
        except Exception as e:
            self._log(f"âŒ Error listing artifacts: {str(e)}")
            import traceback
            self._log(f"   Traceback: {traceback.format_exc()}")
            state["error"] = str(e)
            state["available_artifacts"] = []
        
        return state
    
    def _decide_submission_node(self, state: WrapUpState) -> WrapUpState:
        """Use LLM to decide which artifacts to submit"""
        try:
            available = state.get("available_artifacts", [])
            
            if not available:
                self._log("   No artifacts found to submit")
                state["chosen_artifacts"] = []
                return state
            
            self._log("ðŸ¤” Asking LLM which artifacts to submit...")
            
            # Build prompt with conversation context
            artifact_list = "\n".join([f"  {i+1}. {os.path.basename(p)}" for i, p in enumerate(available)])
            
            # Extract relevant conversation context
            conversation_summary = self._summarize_conversation(state.get("conversation_history", []))
            
            prompt = f"""You are an AI assistant helping to submit work artifacts for evaluation.

TASK DESCRIPTION:
{state.get('task_prompt', 'No task description available')}

WHAT THE AGENT WAS WORKING ON:
{conversation_summary}

AVAILABLE ARTIFACTS (found in sandbox):
{artifact_list}

Your job is to:
1. Review what the agent discussed/created based on the conversation
2. Identify which artifacts are most likely the intended deliverables for this task
3. Choose the artifacts that should be submitted for evaluation
4. Return ONLY a JSON array of artifact numbers (1-indexed)

Example response:
[1, 3, 5]

If none of the artifacts seem relevant, return an empty array: []

Think step-by-step:
- What does the task ask for?
- What did the agent say it was creating?
- Which file types/names match the requirements?
- Are there obvious output files (reports, analysis, results)?

Response (JSON array only):"""

            # Call LLM
            response = self.llm.invoke([HumanMessage(content=prompt)])
            decision_text = response.content.strip()
            
            self._log(f"   LLM decision: {decision_text}")
            state["llm_decision"] = decision_text
            
            # Parse response
            try:
                # Extract JSON array from response
                import re
                json_match = re.search(r'\[(.*?)\]', decision_text, re.DOTALL)
                if json_match:
                    indices = json.loads(json_match.group(0))
                    # Convert to artifact paths (1-indexed to 0-indexed)
                    chosen = [available[i-1] for i in indices if 1 <= i <= len(available)]
                    state["chosen_artifacts"] = chosen
                    
                    self._log(f"   âœ… Chose {len(chosen)} artifacts:")
                    for path in chosen:
                        self._log(f"      â€¢ {os.path.basename(path)}")
                else:
                    self._log("   âš ï¸ Could not parse LLM response, choosing all artifacts")
                    state["chosen_artifacts"] = available
                    
            except Exception as e:
                self._log(f"   âš ï¸ Error parsing decision: {str(e)}, choosing all artifacts")
                state["chosen_artifacts"] = available
            
        except Exception as e:
            self._log(f"âŒ Error in decision node: {str(e)}")
            state["error"] = str(e)
            state["chosen_artifacts"] = state.get("available_artifacts", [])
        
        return state
    
    def _download_artifacts_node(self, state: WrapUpState) -> WrapUpState:
        """Download chosen artifacts from sandbox to local storage"""
        try:
            chosen = state.get("chosen_artifacts", [])
            if not chosen:
                state["downloaded_paths"] = []
                return state
            
            self._log(f"ðŸ“¥ Downloading {len(chosen)} artifacts...")
            
            from livebench.tools.productivity.code_execution_sandbox import SessionSandbox
            
            session_sandbox = SessionSandbox.get_instance()
            sandbox_dir = state.get("sandbox_dir", "")
            
            downloaded = []
            for remote_path in chosen:
                try:
                    local_path = session_sandbox.download_artifact(remote_path, sandbox_dir)
                    downloaded.append(local_path)
                    self._log(f"   âœ… {os.path.basename(local_path)}")
                except Exception as e:
                    self._log(f"   âŒ Failed to download {os.path.basename(remote_path)}: {str(e)}")
            
            state["downloaded_paths"] = downloaded
            self._log(f"   Downloaded {len(downloaded)}/{len(chosen)} artifacts successfully")
            
        except Exception as e:
            self._log(f"âŒ Error downloading artifacts: {str(e)}")
            state["error"] = str(e)
            state["downloaded_paths"] = []
        
        return state
    
    def _submit_work_node(self, state: WrapUpState) -> WrapUpState:
        """Submit downloaded artifacts for evaluation"""
        try:
            downloaded = state.get("downloaded_paths", [])
            if not downloaded:
                self._log("   No artifacts to submit")
                state["submission_result"] = {"success": False, "message": "No artifacts downloaded"}
                return state
            
            self._log(f"ðŸ“¤ Submitting {len(downloaded)} artifacts for evaluation...")
            
            # Call submit_work tool (LangChain StructuredTool - use .invoke())
            from livebench.tools.direct_tools import submit_work
            
            # Create a brief description
            description = f"Auto-submitted {len(downloaded)} artifacts at iteration limit: " + \
                         ", ".join([os.path.basename(p) for p in downloaded])
            
            result = submit_work.invoke({
                "work_output": description,
                "artifact_file_paths": downloaded
            })
            
            state["submission_result"] = result
            
            # Log result
            if isinstance(result, dict):
                if result.get("success"):
                    payment = result.get("payment", 0)
                    self._log(f"   âœ… Submission successful! Payment: ${payment:.2f}")
                else:
                    self._log(f"   âŒ Submission failed: {result.get('message', 'Unknown error')}")
            else:
                self._log(f"   Result: {str(result)[:200]}")
            
        except Exception as e:
            self._log(f"âŒ Error submitting work: {str(e)}")
            state["error"] = str(e)
            state["submission_result"] = {"success": False, "error": str(e)}
        
        return state
    
    def _summarize_conversation(self, messages: List[Dict]) -> str:
        """
        Summarize conversation to extract what the agent was working on
        
        Args:
            messages: List of message dicts with 'role' and 'content'
            
        Returns:
            Summary string
        """
        if not messages:
            return "No conversation history available."
        
        # Extract key information from messages
        summary_parts = []
        
        # Look at last 10 messages for recent context
        recent_messages = messages[-10:] if len(messages) > 10 else messages
        
        for msg in recent_messages:
            role = msg.get("role", "")
            content = str(msg.get("content", ""))
            
            # Extract mentions of file creation, artifact generation, etc.
            if role == "assistant":
                # Look for mentions of creating files
                if any(keyword in content.lower() for keyword in ["creat", "generat", "writ", "sav", "artifact", "file"]):
                    # Truncate to reasonable length
                    truncated = content[:300] + "..." if len(content) > 300 else content
                    summary_parts.append(f"- Agent: {truncated}")
            
            elif role == "user" and "tool result" in content.lower():
                # Look for successful tool executions
                if "artifact_path" in content.lower() or "downloaded" in content.lower():
                    truncated = content[:200] + "..." if len(content) > 200 else content
                    summary_parts.append(f"- Tool result: {truncated}")
        
        if not summary_parts:
            return "Agent was working on the task but no specific file creation details found in recent conversation."
        
        return "\n".join(summary_parts[:5])  # Limit to 5 most relevant items
    
    def _log(self, message: str):
        """Log message to terminal"""
        if self.logger:
            self.logger.terminal_print(message)
        else:
            print(message)
    
    async def run(
        self,
        date: str,
        task: Optional[Dict],
        sandbox_dir: str,
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict:
        """
        Run the wrap-up workflow
        
        Args:
            date: Current date (YYYY-MM-DD)
            task: Current task dictionary (may be None)
            sandbox_dir: Path to sandbox directory for this date
            conversation_history: Agent's conversation messages for context
            
        Returns:
            Final state dictionary with submission results
        """
        self._log("\n" + "="*60)
        self._log("ðŸ”„ WRAP-UP WORKFLOW: Collecting and submitting artifacts")
        self._log("="*60)
        
        # Initialize state
        initial_state = WrapUpState(
            date=date,
            task_id=task.get('task_id', 'unknown') if task else 'unknown',
            task_prompt=task.get('prompt', '') if task else '',
            sandbox_dir=sandbox_dir,
            conversation_history=conversation_history or [],
            available_artifacts=[],
            chosen_artifacts=[],
            downloaded_paths=[],
            submission_result=None,
            error=None,
            llm_decision=None
        )
        
        # Run the graph
        try:
            final_state = await self.graph.ainvoke(initial_state)
            
            self._log("\n" + "="*60)
            self._log("âœ… WRAP-UP WORKFLOW COMPLETE")
            self._log("="*60 + "\n")
            
            return final_state
            
        except Exception as e:
            self._log(f"\nâŒ Wrap-up workflow failed: {str(e)}")
            return {
                "error": str(e),
                "submission_result": None
            }


def create_wrapup_workflow(llm: Optional[ChatOpenAI] = None, logger=None) -> WrapUpWorkflow:
    """
    Factory function to create a wrap-up workflow instance
    
    Args:
        llm: Language model instance (if None, creates default)
        logger: Logger instance for output
        
    Returns:
        WrapUpWorkflow instance
    """
    return WrapUpWorkflow(llm=llm, logger=logger)
