"""
CLI entry point for ClawMode — nanobot gateway with ClawWork economic tracking.

All configuration lives in ~/.nanobot/config.json under ``agents.clawwork``.
No separate livebench config file is needed.

Usage:
    python -m clawmode_integration.cli agent          # interactive chat
    python -m clawmode_integration.cli agent -m "hi"  # single message
    python -m clawmode_integration.cli gateway         # channel gateway
"""

from __future__ import annotations

import asyncio
import os
import signal
from pathlib import Path

import typer
from loguru import logger

app = typer.Typer(name="clawmode", help="ClawMode — nanobot + ClawWork economic tracking")


_ENV_PROVIDER_CANDIDATES = [
    {
        "provider_name": "openrouter",
        "api_key_env": "OPENROUTER_API_KEY",
        "api_base_env": "OPENROUTER_BASE_URL",
        "model_prefixes": ("openrouter/",),
        "default_model": "openrouter/openai/gpt-4o-mini",
    },
    {
        "provider_name": "openai",
        "api_key_env": "OPENAI_API_KEY",
        "api_base_env": "OPENAI_BASE_URL",
        "model_prefixes": ("openai/", "gpt-"),
        "default_model": "openai/gpt-4o-mini",
    },
    {
        "provider_name": "anthropic",
        "api_key_env": "ANTHROPIC_API_KEY",
        "api_base_env": None,
        "model_prefixes": ("anthropic/", "claude-"),
        "default_model": "anthropic/claude-3-5-sonnet-latest",
    },
    {
        "provider_name": "groq",
        "api_key_env": "GROQ_API_KEY",
        "api_base_env": None,
        "model_prefixes": ("groq/",),
        "default_model": "groq/llama-3.1-8b-instant",
    },
    {
        "provider_name": "deepseek",
        "api_key_env": "DEEPSEEK_API_KEY",
        "api_base_env": "DEEPSEEK_API_BASE",
        "model_prefixes": ("deepseek/",),
        "default_model": "deepseek/deepseek-chat",
    },
    {
        "provider_name": "gemini",
        "api_key_env": "GEMINI_API_KEY",
        "api_base_env": None,
        "model_prefixes": ("gemini/",),
        "default_model": "gemini/gemini-1.5-pro",
    },
]


def _load_env_vars() -> None:
    """Load environment variables from .env files if present."""
    try:
        from dotenv import load_dotenv
    except Exception:
        return

    # Current working directory first (common local workflow)
    load_dotenv(dotenv_path=Path.cwd() / ".env", override=False)

    # Project root fallback when invoked from subdirectories
    project_root = Path(__file__).resolve().parent.parent
    load_dotenv(dotenv_path=project_root / ".env", override=False)


@app.callback()
def _callback() -> None:
    """ClawMode — nanobot gateway with ClawWork economic tracking."""
    _load_env_vars()


# -----------------------------------------------------------------------
# Helpers
# -----------------------------------------------------------------------

def _resolve_provider_from_env(model: str):
    """Return provider credentials from environment variables if available."""
    model_l = (model or "").lower()

    # First pass: prefer env key matching current model prefix
    for candidate in _ENV_PROVIDER_CANDIDATES:
        if any(model_l.startswith(prefix) for prefix in candidate["model_prefixes"]):
            api_key = os.getenv(candidate["api_key_env"])
            if api_key:
                return {
                    "api_key": api_key,
                    "api_base": os.getenv(candidate["api_base_env"]) if candidate["api_base_env"] else None,
                    "provider_name": candidate["provider_name"],
                    "default_model": model,
                }

    # Second pass: first available provider env key
    for candidate in _ENV_PROVIDER_CANDIDATES:
        api_key = os.getenv(candidate["api_key_env"])
        if api_key:
            chosen_model = os.getenv("CLAWMODE_MODEL") or candidate["default_model"]
            return {
                "api_key": api_key,
                "api_base": os.getenv(candidate["api_base_env"]) if candidate["api_base_env"] else None,
                "provider_name": candidate["provider_name"],
                "default_model": chosen_model,
            }

    return None

def _make_nanobot_provider(nanobot_config):
    """Create a LiteLLMProvider from nanobot config (mirrors nanobot CLI)."""
    from nanobot.providers.litellm_provider import LiteLLMProvider

    p = nanobot_config.get_provider()
    model = nanobot_config.agents.defaults.model
    api_key = p.api_key if p else None
    api_base = nanobot_config.get_api_base()
    provider_name = nanobot_config.get_provider_name()

    if not api_key and not model.startswith("bedrock/"):
        env_provider = _resolve_provider_from_env(model)
        if env_provider:
            api_key = env_provider["api_key"]
            api_base = env_provider["api_base"] or api_base
            provider_name = env_provider["provider_name"]
            model = env_provider["default_model"]
            logger.warning(
                "Using provider credentials from environment variables "
                f"({provider_name}) because ~/.nanobot/config.json is missing or incomplete"
            )

    if not api_key and not model.startswith("bedrock/"):
        message = (
            "No API key configured in ~/.nanobot/config.json. "
            "Run `nanobot onboard` and set providers.<name>.apiKey, "
            "or export one of OPENROUTER_API_KEY / OPENAI_API_KEY / ANTHROPIC_API_KEY "
            "/ GROQ_API_KEY / DEEPSEEK_API_KEY / GEMINI_API_KEY, "
            "or use a bedrock/* model with AWS credentials."
        )
        logger.error(message)
        typer.secho(message, fg=typer.colors.RED, err=True)
        raise typer.Exit(1)
    return LiteLLMProvider(
        api_key=api_key,
        api_base=api_base,
        default_model=model,
        extra_headers=p.extra_headers if p else None,
        provider_name=provider_name,
    )


def _inject_evaluation_credentials(nano_cfg) -> None:
    """Set EVALUATION_* env vars from nanobot's provider config.

    The LLMEvaluator (livebench/work/llm_evaluator.py:46-55) already
    checks EVALUATION_API_KEY / EVALUATION_API_BASE / EVALUATION_MODEL
    with priority over the OPENAI_* equivalents, so we just populate
    them from nanobot's config before WorkEvaluator is instantiated.
    """
    provider = nano_cfg.get_provider()
    if provider and provider.api_key:
        os.environ.setdefault("EVALUATION_API_KEY", provider.api_key)
        logger.info("Set EVALUATION_API_KEY from nanobot provider config")

    api_base = nano_cfg.get_api_base()
    if api_base:
        os.environ.setdefault("EVALUATION_API_BASE", api_base)

    model = nano_cfg.agents.defaults.model
    if model:
        os.environ.setdefault("EVALUATION_MODEL", model)


def _build_state(nano_cfg):
    """Construct ClawWorkState from the ``agents.clawwork`` plugin config.

    Reads clawwork settings directly from the raw JSON in
    ~/.nanobot/config.json (via clawmode_integration.config), leaving
    nanobot's own Pydantic schema untouched.
    """
    from livebench.agent.economic_tracker import EconomicTracker
    from livebench.work.task_manager import TaskManager
    from livebench.work.evaluator import WorkEvaluator
    from clawmode_integration.config import load_clawwork_config
    from clawmode_integration.tools import ClawWorkState

    # Inject nanobot credentials so LLMEvaluator can use them
    _inject_evaluation_credentials(nano_cfg)

    cw = load_clawwork_config()

    # Derive signature from config or fall back to model name
    sig = cw.signature or nano_cfg.agents.defaults.model.replace("/", "-")
    data_path = str(Path(cw.data_path) / sig) if cw.data_path else str(
        Path("./livebench/data/agent_data") / sig
    )

    # EconomicTracker
    tracker = EconomicTracker(
        signature=sig,
        initial_balance=cw.initial_balance,
        input_token_price=cw.token_pricing.input_price,
        output_token_price=cw.token_pricing.output_price,
        data_path=str(Path(data_path) / "economic"),
    )
    tracker.initialize()

    # TaskManager — only needed for /clawwork tasks; parquet source is default
    task_values_path = cw.task_values_path or None
    tm = TaskManager(
        task_source_type="parquet",
        task_values_path=task_values_path,
    )

    # WorkEvaluator
    evaluator = WorkEvaluator(
        use_llm_evaluation=True,
        meta_prompts_dir=cw.meta_prompts_dir or "./eval/meta_prompts",
    )

    state = ClawWorkState(
        economic_tracker=tracker,
        task_manager=tm,
        evaluator=evaluator,
        signature=sig,
        data_path=data_path,
    )
    return state


def _make_agent_loop(nano_cfg, cron_service=None):
    """Create a ClawWorkAgentLoop from nanobot config.

    Shared by both the ``agent`` and ``gateway`` commands.
    Returns ``(agent_loop, state, bus)``.
    """
    from nanobot.bus.queue import MessageBus
    from nanobot.session.manager import SessionManager
    from clawmode_integration.agent_loop import ClawWorkAgentLoop

    bus = MessageBus()
    provider = _make_nanobot_provider(nano_cfg)
    session_manager = SessionManager(nano_cfg.workspace_path)

    state = _build_state(nano_cfg)

    agent_loop = ClawWorkAgentLoop(
        bus=bus,
        provider=provider,
        workspace=nano_cfg.workspace_path,
        model=nano_cfg.agents.defaults.model,
        temperature=nano_cfg.agents.defaults.temperature,
        max_tokens=nano_cfg.agents.defaults.max_tokens,
        max_iterations=nano_cfg.agents.defaults.max_tool_iterations,
        memory_window=nano_cfg.agents.defaults.memory_window,
        brave_api_key=getattr(nano_cfg.tools.web.search, "api_key", None),
        exec_config=nano_cfg.tools.exec,
        cron_service=cron_service,
        restrict_to_workspace=nano_cfg.tools.restrict_to_workspace,
        session_manager=session_manager,
        mcp_servers=nano_cfg.tools.mcp_servers,
        clawwork_state=state,
    )

    return agent_loop, state, bus


def _check_clawwork_enabled(*, strict: bool = True) -> None:
    """Validate clawwork flag in config.

    If ``strict`` is False, only warn when disabled/missing and continue.
    """
    from clawmode_integration.config import load_clawwork_config

    cw = load_clawwork_config()
    if not cw.enabled:
        message = (
            "ClawWork is not enabled. "
            "Set agents.clawwork.enabled = true in ~/.nanobot/config.json"
        )
        if strict:
            logger.error(message)
            typer.secho(message, fg=typer.colors.RED, err=True)
            raise typer.Exit(1)
        logger.warning(f"{message}; continuing in local agent mode with defaults")


# -----------------------------------------------------------------------
# Agent command (local CLI — like `nanobot agent` but with ClawWork)
# -----------------------------------------------------------------------

@app.command()
def agent(
    message: str = typer.Option(None, "--message", "-m", help="Message to send (omit for interactive mode)"),
    session_id: str = typer.Option("cli:clawwork", "--session", "-s", help="Session ID"),
    markdown: bool = typer.Option(True, "--markdown/--no-markdown", help="Render output as Markdown"),
    logs: bool = typer.Option(False, "--logs/--no-logs", help="Show runtime logs"),
):
    """Chat with the agent locally, with ClawWork economic tracking.

    Works like ``nanobot agent`` but every message is cost-tracked and
    the /clawwork command is available for paid task assignment.

    Examples:
        python -m clawmode_integration.cli agent
        python -m clawmode_integration.cli agent -m "/clawwork Write a market analysis"
        python -m clawmode_integration.cli agent -m "What is my balance?"
    """
    from rich.console import Console
    from nanobot.config.loader import load_config

    if logs:
        logger.enable("nanobot")
    else:
        logger.disable("nanobot")

    _check_clawwork_enabled(strict=False)
    nano_cfg = load_config()

    agent_loop, state, _bus = _make_agent_loop(nano_cfg)
    console = Console()

    def _thinking_ctx():
        if logs:
            from contextlib import nullcontext
            return nullcontext()
        return console.status("[dim]clawwork is thinking...[/dim]", spinner="dots")

    def _print_response(text: str) -> None:
        if not text:
            return
        if markdown:
            from rich.markdown import Markdown
            console.print(Markdown(text))
        else:
            console.print(text)

    balance = state.economic_tracker.get_balance()
    console.print(
        f"[bold]ClawWork[/bold] | {state.signature} | "
        f"balance: ${balance:.2f} | "
        f"status: {state.economic_tracker.get_survival_status()}\n"
    )

    if message:
        # Single-message mode
        async def run_once():
            with _thinking_ctx():
                response = await agent_loop.process_direct(message, session_id)
            _print_response(response)
            await agent_loop.close_mcp()

        asyncio.run(run_once())
    else:
        # Interactive mode
        console.print(
            "Interactive mode — type [bold]exit[/bold] or [bold]Ctrl+C[/bold] to quit\n"
            "Use [bold]/clawwork <instruction>[/bold] to assign a paid task\n"
        )

        def _exit_on_sigint(signum, frame):
            console.print("\nGoodbye!")
            os._exit(0)

        signal.signal(signal.SIGINT, _exit_on_sigint)

        async def run_interactive():
            try:
                while True:
                    try:
                        user_input = await asyncio.to_thread(
                            lambda: console.input("[bold green]you>[/bold green] ")
                        )
                        command = user_input.strip()
                        if not command:
                            continue
                        if command.lower() in ("exit", "quit", "/exit", "/quit", ":q"):
                            console.print("Goodbye!")
                            break

                        with _thinking_ctx():
                            response = await agent_loop.process_direct(command, session_id)
                        _print_response(response)
                    except (KeyboardInterrupt, EOFError):
                        console.print("\nGoodbye!")
                        break
            finally:
                await agent_loop.close_mcp()

        asyncio.run(run_interactive())


# -----------------------------------------------------------------------
# Gateway command (channels — Telegram, Discord, Slack, etc.)
# -----------------------------------------------------------------------

@app.command()
def gateway(
    port: int = typer.Option(18790, "--port", "-p", help="Gateway port"),
):
    """Start the nanobot gateway with ClawWork economic tracking.

    All configuration is read from ~/.nanobot/config.json.
    Enable ClawWork by setting agents.clawwork.enabled = true and
    adjusting token pricing to match your model.

    This launches nanobot's full agent loop with all configured channels
    (Telegram, Discord, Slack, etc.) plus 4 ClawWork economic tools.
    Every LLM call is cost-tracked and a balance footer is appended to
    each response.
    """
    from nanobot.config.loader import load_config, get_data_dir
    from nanobot.channels.manager import ChannelManager
    from nanobot.cron.service import CronService

    _check_clawwork_enabled()
    nano_cfg = load_config()

    cron_store = get_data_dir() / "cron" / "jobs.json"
    cron = CronService(cron_store)

    agent_loop, state, bus = _make_agent_loop(nano_cfg, cron_service=cron)

    channels = ChannelManager(nano_cfg, bus)
    logger.info(
        f"ClawMode gateway starting | agent={state.signature} | "
        f"balance=${state.economic_tracker.get_balance():.2f} | "
        f"tools={agent_loop.tools.tool_names}"
    )

    async def run():
        await cron.start()
        await asyncio.gather(agent_loop.run(), channels.start_all())

    asyncio.run(run())


# -----------------------------------------------------------------------
# Entry point
# -----------------------------------------------------------------------

if __name__ == "__main__":
    app()
