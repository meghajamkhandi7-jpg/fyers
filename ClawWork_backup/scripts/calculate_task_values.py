#!/usr/bin/env python3
"""
Calculate Task Values for GDPVal Dataset

This script:
1. Loads task hour estimates from task_hour_estimates/task_hours.jsonl
2. Loads hourly wage data from task_value_estimates/hourly_wage.csv
3. Uses GPT-5.2 to match each GDPVal occupation to the most appropriate OCC_TITLE in the wage data
4. Calculates task value = hours_estimate * hourly_mean_wage for each task
5. Outputs task values and summary statistics
"""

import os
import json
import csv
from openai import OpenAI
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
from collections import defaultdict

# OpenAI client
client = None

# Configuration
MODEL = "gpt-5.2"
TASK_HOURS_FILE = "./task_hour_estimates/task_hours.jsonl"
HOURLY_WAGE_FILE = "./task_value_estimates/hourly_wage.csv"
OUTPUT_DIR = "./task_value_estimates"
OCCUPATION_MAPPING_FILE = "occupation_to_wage_mapping.json"
TASK_VALUES_FILE = "task_values.jsonl"
SUMMARY_FILE = "value_summary.json"
LOG_FILE = "./task_value_calculation.log"

def log_message(message: str):
    """Log messages to both console and file"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    print(log_entry)
    with open(LOG_FILE, "a") as f:
        f.write(log_entry + "\n")

def load_task_hours() -> List[Dict[str, Any]]:
    """Load task hour estimates from JSONL file"""
    log_message(f"Loading task hour estimates from {TASK_HOURS_FILE}")
    tasks = []
    with open(TASK_HOURS_FILE, 'r') as f:
        for line in f:
            try:
                task = json.loads(line.strip())
                tasks.append(task)
            except Exception as e:
                log_message(f"Warning: Could not parse line: {str(e)}")
    log_message(f"Loaded {len(tasks)} tasks")
    return tasks

def load_wage_data() -> List[Dict[str, str]]:
    """Load hourly wage data from CSV file"""
    log_message(f"Loading wage data from {HOURLY_WAGE_FILE}")
    wage_data = []
    with open(HOURLY_WAGE_FILE, 'r') as f:
        reader = csv.DictReader(f, delimiter='\t')
        for row in reader:
            # Filter out entries with missing wage data (marked as '*' or empty string)
            h_mean = row.get('H_MEAN', '').strip()
            if h_mean and h_mean != '*':
                try:
                    wage_data.append({
                        'occ_title': row['OCC_TITLE'],
                        'h_mean': float(h_mean)
                    })
                except ValueError:
                    # Skip rows where H_MEAN can't be converted to float
                    log_message(f"Warning: Skipping row with invalid H_MEAN: {row['OCC_TITLE']}")
                    continue
    log_message(f"Loaded {len(wage_data)} wage entries (excluding entries with missing data)")
    return wage_data

def get_unique_occupations(tasks: List[Dict[str, Any]]) -> List[str]:
    """Extract unique occupations from tasks"""
    occupations = set()
    for task in tasks:
        occ = task.get('metadata', {}).get('occupation')
        if occ:
            occupations.add(occ)
    log_message(f"Found {len(occupations)} unique occupations")
    return sorted(list(occupations))

def create_occupation_matching_prompt(
    gdpval_occupation: str,
    wage_occupations: List[str]
) -> str:
    """Create prompt for GPT-5.2 to match occupations"""

    # Format the wage occupations list (show first 100 to fit in context)
    wage_list = "\n".join([f"- {occ}" for occ in wage_occupations[:200]])

    prompt = f"""You are an expert in occupational classification and labor statistics. Your task is to match a GDPVal occupation title to the most appropriate occupation title from the U.S. Bureau of Labor Statistics (BLS) wage data.

**GDPVal Occupation to Match:**
"{gdpval_occupation}"

**Available BLS Occupation Titles:**
{wage_list}

**YOUR TASK:**
Find the single best matching BLS occupation title for the GDPVal occupation. Consider:

1. **Direct Match**: Look for exact or nearly exact matches first
2. **Semantic Similarity**: Consider occupations with similar job functions, responsibilities, and skill requirements
3. **Specificity**: If the GDPVal occupation is specific, prefer a specific BLS match. If it's general, a general BLS category may be appropriate
4. **Industry Context**: Consider the typical industry and work context
5. **Hierarchical Relationships**: Parent categories can be appropriate if no specific match exists

**IMPORTANT GUIDELINES:**
- Choose the MOST SPECIFIC match that accurately represents the occupation
- If multiple matches seem equally good, choose the more specific one
- The match should be semantically meaningful (similar job functions and responsibilities)
- Consider both the occupation name and what the occupation actually does

**OUTPUT FORMAT:**
Provide your response as a JSON object:

```json
{{
  "gdpval_occupation": "{gdpval_occupation}",
  "matched_bls_title": "The exact BLS occupation title from the list above",
  "confidence": "high|medium|low",
  "reasoning": "Brief explanation of why this is the best match, considering job functions and responsibilities"
}}
```

**CRITICAL:**
- The matched_bls_title MUST be an exact match (character-for-character) of one of the BLS titles listed above
- Do not modify or paraphrase the BLS title
- If no good match exists, choose the closest parent category

Please provide your matching now."""

    return prompt

def match_occupation_to_wage(
    gdpval_occupation: str,
    wage_data: List[Dict[str, str]]
) -> Optional[Dict[str, Any]]:
    """Use GPT-5.2 to match a GDPVal occupation to a BLS wage occupation"""
    global client
    if client is None:
        client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    log_message(f"Matching occupation: {gdpval_occupation}")

    # Get list of wage occupation titles
    wage_titles = [w['occ_title'] for w in wage_data]

    # Create matching prompt
    prompt = create_occupation_matching_prompt(gdpval_occupation, wage_titles)

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert in occupational classification who specializes in matching job titles across different classification systems. You provide accurate, well-reasoned occupation matches based on job functions and responsibilities."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)

        # Find the matched wage entry
        matched_title = result['matched_bls_title']
        matched_wage = next((w for w in wage_data if w['occ_title'] == matched_title), None)

        if matched_wage:
            mapping = {
                'gdpval_occupation': gdpval_occupation,
                'bls_occupation': matched_wage['occ_title'],
                'hourly_wage': matched_wage['h_mean'],
                'confidence': result['confidence'],
                'reasoning': result['reasoning'],
                'matched_at': datetime.now().isoformat(),
                'model': MODEL
            }
            log_message(f"‚úÖ Matched '{gdpval_occupation}' -> '{matched_wage['occ_title']}' (${matched_wage['h_mean']}/hr)")
            return mapping
        else:
            log_message(f"‚ùå ERROR: Matched title '{matched_title}' not found in wage data")
            return None

    except Exception as e:
        log_message(f"‚ùå ERROR matching occupation '{gdpval_occupation}': {str(e)}")
        return None

def create_occupation_mappings(
    occupations: List[str],
    wage_data: List[Dict[str, str]],
    output_dir: Path
) -> Dict[str, Dict[str, Any]]:
    """Create mappings for all occupations"""

    mapping_file = output_dir / OCCUPATION_MAPPING_FILE

    # Load existing mappings if available
    mappings = {}
    if mapping_file.exists():
        log_message(f"Loading existing occupation mappings from {mapping_file}")
        with open(mapping_file, 'r') as f:
            data = json.load(f)
            mappings = {m['gdpval_occupation']: m for m in data}
        log_message(f"Loaded {len(mappings)} existing mappings")

    # Match any unmapped occupations
    for occupation in occupations:
        if occupation not in mappings:
            mapping = match_occupation_to_wage(occupation, wage_data)
            if mapping:
                mappings[occupation] = mapping

                # Save immediately after each mapping (streaming approach)
                with open(mapping_file, 'w') as f:
                    json.dump(list(mappings.values()), f, indent=2)

                # Rate limiting
                import time
                time.sleep(1)

    log_message(f"Total occupation mappings: {len(mappings)}")
    return mappings

def calculate_task_values(
    tasks: List[Dict[str, Any]],
    occupation_mappings: Dict[str, Dict[str, Any]],
    output_dir: Path
) -> List[Dict[str, Any]]:
    """Calculate value for each task"""

    log_message("Calculating task values...")

    task_values = []
    success_count = 0
    missing_mapping_count = 0

    for task in tasks:
        occupation = task.get('metadata', {}).get('occupation')
        hours_estimate = task.get('hours_estimate', 0)

        if not occupation or occupation not in occupation_mappings:
            log_message(f"‚ö†Ô∏è  No wage mapping for occupation: {occupation}")
            missing_mapping_count += 1
            continue

        mapping = occupation_mappings[occupation]
        hourly_wage = mapping['hourly_wage']
        task_value = hours_estimate * hourly_wage

        task_value_entry = {
            'task_id': task['task_id'],
            'occupation': occupation,
            'hours_estimate': hours_estimate,
            'hourly_wage': hourly_wage,
            'task_value_usd': round(task_value, 2),
            'bls_occupation': mapping['bls_occupation'],
            'confidence': mapping['confidence'],
            'sector': task.get('metadata', {}).get('sector', 'Unknown'),
            'task_summary': task.get('task_summary', '')
        }

        task_values.append(task_value_entry)
        success_count += 1

    log_message(f"‚úÖ Calculated values for {success_count} tasks")
    if missing_mapping_count > 0:
        log_message(f"‚ö†Ô∏è  Skipped {missing_mapping_count} tasks due to missing occupation mappings")

    # Save task values to JSONL
    output_file = output_dir / TASK_VALUES_FILE
    with open(output_file, 'w') as f:
        for task_value in task_values:
            f.write(json.dumps(task_value) + "\n")

    log_message(f"Saved task values to {output_file}")

    return task_values

def generate_value_summary(
    task_values: List[Dict[str, Any]],
    output_dir: Path
):
    """Generate summary statistics for task values"""

    log_message("Generating value summary...")

    if not task_values:
        log_message("No task values to summarize")
        return

    # Overall statistics
    total_value = sum(tv['task_value_usd'] for tv in task_values)
    avg_value = total_value / len(task_values)
    values = [tv['task_value_usd'] for tv in task_values]
    min_value = min(values)
    max_value = max(values)

    # Group by occupation
    occupation_stats = defaultdict(lambda: {
        'task_count': 0,
        'total_hours': 0,
        'total_value': 0,
        'avg_hourly_wage': 0,
        'bls_occupation': '',
        'tasks': []
    })

    for tv in task_values:
        occ = tv['occupation']
        occupation_stats[occ]['task_count'] += 1
        occupation_stats[occ]['total_hours'] += tv['hours_estimate']
        occupation_stats[occ]['total_value'] += tv['task_value_usd']
        occupation_stats[occ]['avg_hourly_wage'] = tv['hourly_wage']
        occupation_stats[occ]['bls_occupation'] = tv['bls_occupation']
        occupation_stats[occ]['tasks'].append({
            'task_id': tv['task_id'],
            'hours': tv['hours_estimate'],
            'value': tv['task_value_usd']
        })

    # Create summary
    summary = {
        "generation_date": datetime.now().isoformat(),
        "model_used": MODEL,
        "total_tasks_valued": len(task_values),
        "total_value_usd": round(total_value, 2),
        "average_value_per_task": round(avg_value, 2),
        "min_value_usd": round(min_value, 2),
        "max_value_usd": round(max_value, 2),
        "occupation_breakdown": [
            {
                "gdpval_occupation": occ,
                "bls_occupation": stats['bls_occupation'],
                "task_count": stats['task_count'],
                "total_hours": round(stats['total_hours'], 2),
                "avg_hours_per_task": round(stats['total_hours'] / stats['task_count'], 2),
                "hourly_wage": round(stats['avg_hourly_wage'], 2),
                "total_value_usd": round(stats['total_value'], 2),
                "avg_value_per_task": round(stats['total_value'] / stats['task_count'], 2)
            }
            for occ, stats in sorted(
                occupation_stats.items(),
                key=lambda x: x[1]['total_value'],
                reverse=True
            )
        ]
    }

    # Save summary
    summary_file = output_dir / SUMMARY_FILE
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)

    log_message(f"üìä Value Summary:")
    log_message(f"   Total tasks valued: {len(task_values)}")
    log_message(f"   Total value: ${total_value:,.2f}")
    log_message(f"   Average value per task: ${avg_value:.2f}")
    log_message(f"   Value range: ${min_value:.2f} - ${max_value:.2f}")
    log_message(f"   Summary saved to: {summary_file}")

def main():
    """Main execution function"""
    log_message("=" * 80)
    log_message("Starting Task Value Calculation")
    log_message("=" * 80)

    # Check for API key
    if not os.environ.get("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEY environment variable not set!")

    # Create output directory
    output_dir = Path(OUTPUT_DIR)
    output_dir.mkdir(exist_ok=True)

    # Load data
    tasks = load_task_hours()
    wage_data = load_wage_data()

    # Get unique occupations
    occupations = get_unique_occupations(tasks)

    # Create occupation mappings (uses GPT-5.2)
    log_message("\n" + "=" * 80)
    log_message("Step 1: Matching GDPVal Occupations to BLS Wage Data")
    log_message("=" * 80)
    occupation_mappings = create_occupation_mappings(occupations, wage_data, output_dir)

    # Calculate task values
    log_message("\n" + "=" * 80)
    log_message("Step 2: Calculating Task Values")
    log_message("=" * 80)
    task_values = calculate_task_values(tasks, occupation_mappings, output_dir)

    # Generate summary
    log_message("\n" + "=" * 80)
    log_message("Step 3: Generating Summary Report")
    log_message("=" * 80)
    generate_value_summary(task_values, output_dir)

    log_message("\n" + "=" * 80)
    log_message("‚úÖ Task Value Calculation Complete!")
    log_message("=" * 80)
    log_message(f"Output files:")
    log_message(f"  - Occupation mappings: {output_dir / OCCUPATION_MAPPING_FILE}")
    log_message(f"  - Task values: {output_dir / TASK_VALUES_FILE}")
    log_message(f"  - Summary: {output_dir / SUMMARY_FILE}")
    log_message("=" * 80)

if __name__ == "__main__":
    main()
